{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0347a8b-6fed-4103-bc47-91410261d2a1",
   "metadata": {
    "id": "1wa-6_cyNgQu"
   },
   "source": [
    "## Giving google colab access to google drive \n",
    "Only needed if you are using google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DabYOnP5HmzA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DabYOnP5HmzA",
    "outputId": "28cd7b02-1452-4bad-8612-e2fff6b5c5c0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0413a2-cad2-457f-8e72-9b9b2945874e",
   "metadata": {},
   "source": [
    "## Guide\n",
    "If you are useing google colab you will need to connect the google drive above. (Only needs to be done ones)\n",
    "\n",
    "After that you will need to run the setup code to make the predication environment.\n",
    "\n",
    "After everthing has been setup you will find the predict image options at the botton as well as the GUI and imageg compatabilty function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84246e-2162-4955-bd40-7fd0f2614bc4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6827e8-e6a8-4a8d-a68f-3f4a57d38aa1",
   "metadata": {
    "id": "3f4e9f00-d561-48cf-8e26-75f7e2348329"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "# Suppressing warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Importing plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Importing utility functions\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "\n",
    "# Importing image processing libraries\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# Importing model-related modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import *\n",
    "from keras.callbacks import *\n",
    "\n",
    "# Importing pre-trained model and preprocessing function\n",
    "from keras.applications.densenet import DenseNet121, preprocess_input\n",
    "\n",
    "## Finding the amount of breeds and total images\n",
    "\n",
    "# Define the directory containing breed images\n",
    "images_directory = \"D:/Programming/archive/images/Images\"\n",
    "\n",
    "# Get a list of all breeds from the directory\n",
    "breed_list = os.listdir(images_directory)\n",
    "\n",
    "# Count the number of breeds\n",
    "num_classes = len(breed_list)\n",
    "\n",
    "# Count the total number of images for all breeds\n",
    "n_total_images = 0\n",
    "for breed in breed_list:\n",
    "    # Get the path to the current breed directory\n",
    "    breed_directory = os.path.join(images_directory, breed)\n",
    "    # Count the number of images in the current breed directory\n",
    "    n_images_in_breed = len(os.listdir(breed_directory))\n",
    "    # Add the count to the total number of images\n",
    "    n_total_images += n_images_in_breed\n",
    "\n",
    "## Reformatting the images. Only run when need new images ##\n",
    "\n",
    "def Image_Reform():\n",
    "    %%time\n",
    "    \n",
    "    # Create a directory to store data if it doesn't exist\n",
    "    data_dir = 'data'\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    \n",
    "    # Create subdirectories for each breed\n",
    "    for breed in breed_list:\n",
    "        breed_dir = os.path.join(data_dir, breed)\n",
    "        if not os.path.exists(breed_dir):\n",
    "            os.mkdir(breed_dir)\n",
    "    \n",
    "    print('Created {} folders to store cropped images of the different breeds.'.format(len(os.listdir(data_dir))))\n",
    "    \n",
    "    # Iterate through each breed directory and process images\n",
    "    for breed in os.listdir(data_dir):\n",
    "        breed_annotation_dir = os.path.join('D:/Programming/archive/annotations/Annotation', breed)\n",
    "        breed_image_dir = os.path.join('D:/Programming/archive/images/Images', breed)\n",
    "    \n",
    "        # Iterate through each file in the breed's annotation directory\n",
    "        for file in os.listdir(breed_annotation_dir):\n",
    "            annotation_path = os.path.join(breed_annotation_dir, file)\n",
    "            image_path = os.path.join(breed_image_dir, '{}.jpg'.format(file))\n",
    "    \n",
    "            # Open image and parse annotation XML\n",
    "            img = Image.open(image_path)\n",
    "            tree = ET.parse(annotation_path)\n",
    "    \n",
    "            # Extract bounding box coordinates\n",
    "            xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n",
    "            xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n",
    "            ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n",
    "            ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n",
    "    \n",
    "            # Crop, convert, and resize image\n",
    "            cropped_img = img.crop((xmin, ymin, xmax, ymax))\n",
    "            cropped_img = cropped_img.convert('RGB')\n",
    "            cropped_img = cropped_img.resize((224, 224))\n",
    "    \n",
    "            # Save the processed image to the appropriate breed directory\n",
    "            save_path = os.path.join(data_dir, breed, '{}.jpg'.format(file))\n",
    "            cropped_img.save(save_path)\n",
    "\n",
    "## Mapping the dataset\n",
    "\n",
    "# Initialize dictionaries to store mappings\n",
    "label_maps = {}\n",
    "label_maps_rev = {}\n",
    "\n",
    "# Iterate over the breed list and assign indices\n",
    "for index, breed_name in enumerate(breed_list):\n",
    "    # Map breed names to indices\n",
    "    label_maps[breed_name] = index\n",
    "    # Map indices to breed names\n",
    "    label_maps_rev[index] = breed_name\n",
    "\n",
    "## Function to display images\n",
    "\n",
    "def show_dir_images(breed, n_to_show):\n",
    "    # Set up figure size for displaying images\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    \n",
    "    # Define the directory where images of the specified breed are located\n",
    "    img_dir = \"D:/Programming/archive/images/Images/{}/\".format(breed)\n",
    "    \n",
    "    # Get a list of image filenames in the specified directory, limited by n_to_show\n",
    "    images = os.listdir(img_dir)[:n_to_show]\n",
    "    \n",
    "    # Calculate the number of rows needed to display all images\n",
    "    num_rows = math.ceil(n_to_show / 4)\n",
    "    \n",
    "    # Loop through the images and display them\n",
    "    for i in range(n_to_show):\n",
    "        # Read the image using matplotlib\n",
    "        img = mpimg.imread(img_dir + images[i])\n",
    "        \n",
    "        # Create a subplot for the current image\n",
    "        plt.subplot(num_rows, 4, i + 1)\n",
    "        \n",
    "        # Display the image\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        # Turn off axis labels\n",
    "        plt.axis('off')\n",
    "\n",
    "def paths_labels_and_targets():\n",
    "    \"\"\"\n",
    "    Collects file paths, labels, and target values.\n",
    "    \"\"\"\n",
    "    paths, labels, targets = [], [], []\n",
    "    \n",
    "    # Iterating through each breed and its respective images\n",
    "    for breed in breed_list:\n",
    "        base_name = f\"./data/{breed}/\"\n",
    "        for img_name in os.listdir(base_name):\n",
    "            paths.append(f\"{base_name}{img_name}\")  # Adding the file path\n",
    "            labels.append(breed)  # Adding the breed label\n",
    "            targets.append(label_maps[breed])  # Adding the target value\n",
    "    \n",
    "    return paths, labels, targets\n",
    "\n",
    "# Getting paths, labels, and targets\n",
    "paths, labels, targets = paths_labels_and_targets()\n",
    "\n",
    "# Asserting equal lengths for paths, labels, and targets\n",
    "assert len(paths) == len(labels) == len(targets)\n",
    "\n",
    "# Converting targets to categorical\n",
    "targets = to_categorical(targets, num_classes=num_classes)\n",
    "\n",
    "# Define the batch size globally\n",
    "batch_size = 64\n",
    "\n",
    "class ImageGenerator(Sequence):\n",
    "    def __init__(self, paths, targets, batch_size, shape, augment=False):\n",
    "        \"\"\"\n",
    "        Constructor for the ImageGenerator class.\n",
    "\n",
    "        Args:\n",
    "        - paths: List of file paths to images.\n",
    "        - targets: List of targets corresponding to the images.\n",
    "        - batch_size: Size of each batch.\n",
    "        - shape: Shape of the images.\n",
    "        - augment: Boolean indicating whether to apply data augmentation.\n",
    "        \"\"\"\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Computes the number of batches in the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - The number of batches.\n",
    "        \"\"\"\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one batch of data.\n",
    "\n",
    "        Args:\n",
    "        - idx: Index of the batch.\n",
    "\n",
    "        Returns:\n",
    "        - Tuple (X, y) where X is a batch of images and y is their corresponding labels.\n",
    "        \"\"\"\n",
    "        batch_paths = self.paths[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        x = np.zeros((len(batch_paths), self.shape[0], self.shape[1], self.shape[2]), dtype=np.float32)\n",
    "        y = np.zeros((self.batch_size, num_classes, 1))\n",
    "        for i, path in enumerate(batch_paths):\n",
    "            x[i] = self.__load_image(path)\n",
    "        y = self.targets[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        return x, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Iterates over the batches.\n",
    "\n",
    "        Yields:\n",
    "        - Each batch of data.\n",
    "        \"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "\n",
    "    def __load_image(self, path):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses an image.\n",
    "\n",
    "        Args:\n",
    "        - path: File path of the image.\n",
    "\n",
    "        Returns:\n",
    "        - Preprocessed image.\n",
    "        \"\"\"\n",
    "        image = imread(path)\n",
    "        image = preprocess_input(image)\n",
    "        if self.augment:\n",
    "            seq = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5),\n",
    "                    iaa.Flipud(0.5),\n",
    "                    iaa.CropAndPad(percent=(-0.25, 0.25)),\n",
    "                    iaa.Crop(percent=(0, 0.1)),\n",
    "                    iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.5))),\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-180, 180),\n",
    "                        shear=(-8, 8)\n",
    "                    )\n",
    "                ])\n",
    "            ], random_order=True)\n",
    "            #image = seq.augment_image(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "# Split the paths and targets into training and validation sets\n",
    "train_paths, val_paths, train_targets, val_targets = train_test_split(\n",
    "    paths,  # List of file paths\n",
    "    targets,  # List of corresponding targets\n",
    "    test_size=0.15,  # Percentage of data to use for validation\n",
    "    random_state=1029  # Seed for reproducibility\n",
    ")\n",
    "\n",
    "# Define generators for training and validation data\n",
    "# ImageGenerator is assumed to be a custom class for generating batches of images\n",
    "# Parameters:\n",
    "# - paths: List of file paths\n",
    "# - targets: List of corresponding targets\n",
    "# - batch_size: Size of each batch\n",
    "# - shape: Shape of the input images (height, width, channels)\n",
    "# - augment: Whether to apply data augmentation (e.g., rotation, flipping) to training images\n",
    "train_gen = ImageGenerator(\n",
    "    train_paths,\n",
    "    train_targets,\n",
    "    batch_size=32,\n",
    "    shape=(224, 224, 3),\n",
    "    augment=True  # Augment training data\n",
    ")\n",
    "val_gen = ImageGenerator(\n",
    "    val_paths,\n",
    "    val_targets,\n",
    "    batch_size=32,\n",
    "    shape=(224, 224, 3),\n",
    "    augment=False  # Do not augment validation data\n",
    ")\n",
    "\n",
    "# Define the input shape\n",
    "inp = Input((224, 224, 3))\n",
    "\n",
    "# Load DenseNet121 as backbone, excluding the top layer\n",
    "# and using pre-trained weights\n",
    "backbone = DenseNet121(input_tensor=inp,\n",
    "                       weights=\"D:/Programming/DenseNet/archive/DenseNet-BC-121-32-no-top.h5\",\n",
    "                       include_top=False)\n",
    "\n",
    "# Get the output of the backbone model\n",
    "x = backbone.output\n",
    "\n",
    "# Apply Global Average Pooling to reduce dimensionality\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer with 1024 neurons and ReLU activation\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "# Apply Dropout to avoid overfitting\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add another fully connected layer with 512 neurons and ReLU activation\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "\n",
    "# Apply Dropout again\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Final output layer with softmax activation for classification\n",
    "outp = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# Define the model with input and output layers\n",
    "model = Model(inp, outp)\n",
    "\n",
    "## Training\n",
    "\n",
    "def train(epochs_in):\n",
    "    for layer in model.layers[:-6]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"acc\"])\n",
    "    \n",
    "    history = model.fit_generator(generator=train_gen,\n",
    "                                  steps_per_epoch=len(train_gen),\n",
    "                                  validation_data=val_gen,\n",
    "                                  validation_steps=len(val_gen),\n",
    "                                  epochs=epochs_in)\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (6,6)\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.plot(epochs, acc, 'red', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'blue', label='Validation acc')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.plot(epochs, loss, 'red', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'blue', label='Validation loss')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    for layer in model.layers[:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # a check point callback to save our best weights\n",
    "    checkpoint = ModelCheckpoint('dog_breed_classifier_model.h5',\n",
    "                                 monitor='val_acc',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max',\n",
    "                                 save_weights_only=True)\n",
    "    \n",
    "    # a reducing lr callback to reduce lr when val_loss doesn't increase\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                       patience=1, verbose=1, mode='min',\n",
    "                                       min_delta=0.0001, cooldown=2, min_lr=1e-7)\n",
    "    \n",
    "    # for early stop\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    \n",
    "    history = model.fit(x=train_gen,\n",
    "                        steps_per_epoch=len(train_gen),\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=len(val_gen),\n",
    "                        epochs=epochs_in,\n",
    "                        callbacks=[checkpoint, reduce_lr, early_stop])\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (6,6)\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.plot(epochs, acc, 'red', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'blue', label='Validation acc')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.plot(epochs, loss, 'red', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'blue', label='Validation loss')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(max(val_acc))\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save('trained_model.h5')\n",
    "    \n",
    "    # Save training history to a CSV file\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.to_csv('training_history.csv', index=False)\n",
    "\n",
    "## Loading the previusly saved training data \n",
    "\n",
    "def load_training_data(model_path, history_path):\n",
    "    # Load the trained model\n",
    "    loaded_model = load_model(model_path)\n",
    "    \n",
    "    # Load training history from CSV file\n",
    "    history_df = pd.read_csv(history_path)\n",
    "    history = history_df.to_dict(orient='list')\n",
    "\n",
    "    return loaded_model, history\n",
    "\n",
    "## Function to download and predic the images ##\n",
    "\n",
    "def download_and_predict(url, filename):\n",
    "    \"\"\"\n",
    "    Downloads an image from a given URL, preprocesses it for prediction,\n",
    "    displays the image, and predicts the top 5 classes.\n",
    "\n",
    "    Parameters:\n",
    "    - url: The URL of the image to download.\n",
    "    - filename: The filename to save the downloaded image.\n",
    "    \"\"\"\n",
    "    # Download the image from the given URL and save it\n",
    "    os.system(\"curl -s {} -o {}\".format(url, filename))\n",
    "    \n",
    "    # Open the image, convert it to RGB, and resize it\n",
    "    img = Image.open(filename)\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((224, 224))\n",
    "    img.save(filename)  # Overwrite the original image with the resized one\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Preprocess the image for prediction\n",
    "    img = imread(filename)\n",
    "    img = preprocess_input(img)\n",
    "    \n",
    "    # Predict the top 5 classes\n",
    "    probs = model.predict(np.expand_dims(img, axis=0))\n",
    "    for idx in probs.argsort()[0][::-1][:5]:\n",
    "        print(\"{:.2f}%\".format(probs[0][idx]*100), \"\\t\", label_maps_rev[idx].split(\"-\")[-1])\n",
    "\n",
    "    os.remove(filename)\n",
    "\n",
    "## Function to predict an image that is already downloaded\n",
    "\n",
    "def predict(filename):\n",
    "    # Opening the image file and preparing it for prediction\n",
    "    img = Image.open(filename)\n",
    "    img = img.convert('RGB')  # Convert image to RGB format\n",
    "    img = img.resize((224, 224))  # Resize the image to match model's input size\n",
    "    filename = \"Com_\"+filename\n",
    "    img.save(filename)  # Overwrite the original file with the formatted image\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Preprocess the image for prediction\n",
    "    img_array = imread(filename)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    # Make predictions using the model\n",
    "    probabilities = model.predict(np.expand_dims(img_array, axis=0))\n",
    "\n",
    "    # Display the top 5 predicted classes and their probabilities\n",
    "    for idx in probabilities.argsort()[0][::-1][:5]:\n",
    "        print(\"{:.2f}%\".format(probabilities[0][idx] * 100), \"\\t\", label_maps_rev[idx].split(\"-\")[-1])\n",
    "        \n",
    "    os.remove(filename)\n",
    "\n",
    "## GUI\n",
    "\n",
    "def GUI():\n",
    "                # Predict image online:       # Predict image local:          Train:\n",
    "                # PIO_entry = Image url       # PIL_entry = File name         # T_entry = number of epochs\n",
    "                # PIO_entry2 = File name \n",
    "    \n",
    "    global Color\n",
    "    Color = \"Dark Gray\"\n",
    "    \n",
    "    def PIO():\n",
    "        # Funcation to call the download and predict funcation with the needed data\n",
    "        url = PIO_entry.get()\n",
    "        filename = PIO_entry2.get()\n",
    "        download_and_predict(url,filename)\n",
    "        \n",
    "    def PIL():\n",
    "        # Funcation to call the predict funcation with the needed data\n",
    "        filename = PIL_entry.get()\n",
    "        predict(filename)\n",
    "    \n",
    "    def T():\n",
    "        # Funcation to call the train funcation with the needed data\n",
    "        epochs_in= T_entry.get()\n",
    "        train(epochs_in)\n",
    "    \n",
    "    def back1():\n",
    "        # Removing all the elements of the predict image online menu \n",
    "        PIO_label0.destroy()\n",
    "        PIO_label1.destroy()\n",
    "        PIO_label2.destroy()\n",
    "        PIO_label3.destroy()\n",
    "        PIO_label4.destroy()\n",
    "        PIO_entry.destroy()\n",
    "        PIO_entry2.destroy()\n",
    "        PIO_Back.destroy()\n",
    "        PIO_submit_button.destroy()\n",
    "        main_menu()\n",
    "    \n",
    "    def back2():\n",
    "        # Removing all the elements of the predict image local menu \n",
    "        PIL_label0.destroy()\n",
    "        PIL_label1.destroy()\n",
    "        PIL_label2.destroy()\n",
    "        PIL_label3.destroy()\n",
    "        PIL_entry.destroy()\n",
    "        PIL_Back.destroy()\n",
    "        PIL_submit_button.destroy()\n",
    "        main_menu()\n",
    "    \n",
    "    def back3():\n",
    "        # Removing all the elements of the train menu \n",
    "        T_label0.destroy()\n",
    "        T_label1.destroy()\n",
    "        T_label2.destroy()\n",
    "        T_label3.destroy()\n",
    "        T_entry.destroy()\n",
    "        T_Back.destroy()\n",
    "        T_submit_button.destroy() \n",
    "        main_menu()\n",
    "        \n",
    "    def button1_clicked():\n",
    "        # Removing all the elements of the main menu \n",
    "        label0.destroy()\n",
    "        label1.destroy()\n",
    "        label2.destroy()\n",
    "        button1.destroy()\n",
    "        button2.destroy()\n",
    "        button3.destroy()\n",
    "        button4.destroy() \n",
    "        \n",
    "        # Creating the Predict image online menu\n",
    "        global PIO_label0, PIO_label1, PIO_label2, PIO_label3, PIO_entry, PIO_label4, PIO_entry2, PIO_submit_button, PIO_Back\n",
    "        PIO_label0 = tk.Label(root, text=\"\", bg=Color, font=(\"Arial\", 10), padx=1, pady=1, height=1, width = 25)\n",
    "        PIO_label0.pack()\n",
    "        PIO_label1 = tk.Label(root, text=\"Predict Image Online\", bg=\"gray\", fg=\"white\", font=(\"Arial\", 25), relief=\"ridge\", padx=10, pady=10, height=1, width = 25)\n",
    "        PIO_label1.pack()\n",
    "        PIO_label2 = tk.Label(root, text=\"\", bg=Color, font=(\"Arial\", 25), padx=5, pady=10, height=1, width = 25)\n",
    "        PIO_label2.pack()\n",
    "    \n",
    "        PIO_label3 = tk.Label(root, text=\"Image url\", bg=Color, fg=\"white\", font=(\"Arial\", 15), padx=10, pady=10, height=1, width = 25)\n",
    "        PIO_label3.pack()\n",
    "    \n",
    "        PIO_entry = tk.Entry(root, bg=\"white\", fg=\"black\", font=(\"Arial\", 10), relief=\"ridge\", width=65)\n",
    "        PIO_entry.pack(pady = 10)\n",
    "    \n",
    "        PIO_label4 = tk.Label(root, text=\"File Name\", bg=Color, fg=\"white\", font=(\"Arial\", 15), padx=10, pady=10, height=1, width = 25)\n",
    "        PIO_label4.pack()\n",
    "    \n",
    "        PIO_entry2 = tk.Entry(root, bg=\"white\", fg=\"black\", font=(\"Arial\", 10), relief=\"ridge\", width=65)\n",
    "        PIO_entry2.pack(pady = 10)\n",
    "    \n",
    "        PIO_submit_button = tk.Button(root, text=\"Submit\", command=PIO, font=(\"Arial\", 15), width=25, height=2, activebackground=\"light green\", activeforeground=\"black\", bg=\"gray\", fg=\"white\")\n",
    "        PIO_submit_button.pack(pady = 10)\n",
    "    \n",
    "        PIO_Back = tk.Button(root, text=\"Back\", command=back1, font=(\"Arial\", 15), width=25, height=2, activebackground=\"light green\", activeforeground=\"black\", bg=\"gray\", fg=\"white\")\n",
    "        PIO_Back.pack(pady = 10)\n",
    "        \n",
    "    def button2_clicked():\n",
    "        # Removing all the elements of the main menu \n",
    "        label0.destroy()\n",
    "        label1.destroy()\n",
    "        label2.destroy()\n",
    "        button1.destroy()\n",
    "        button2.destroy()\n",
    "        button3.destroy()\n",
    "        button4.destroy() \n",
    "        \n",
    "        # Creating the Predict image local menu\n",
    "        global PIL_label0, PIL_label1, PIL_label2, PIL_label3, PIL_entry, PIL_submit_button, PIL_Back\n",
    "        PIL_label0 = tk.Label(root, text=\"\", bg=Color, font=(\"Arial\", 10), padx=1, pady=1, height=1, width = 25)\n",
    "        PIL_label0.pack()\n",
    "        PIL_label1 = tk.Label(root, text=\"Predict Image Local\", bg=\"gray\", fg=\"white\", font=(\"Arial\", 25), relief=\"ridge\", padx=10, pady=10, height=1, width = 25)\n",
    "        PIL_label1.pack()\n",
    "        PIL_label2 = tk.Label(root, text=\"\", bg=Color, font=(\"Arial\", 25), padx=5, pady=10, height=1, width = 25)\n",
    "        PIL_label2.pack()\n",
    "        \n",
    "        PIL_label3 = tk.Label(root, text=\"File Name\", bg=Color, fg=\"white\", font=(\"Arial\", 15), padx=10, pady=10, height=1, width = 25)\n",
    "        PIL_label3.pack()\n",
    "        \n",
    "        PIL_entry = tk.Entry(root, bg=\"white\", fg=\"black\", font=(\"Arial\", 10), relief=\"ridge\", width=65)\n",
    "        PIL_entry.pack(pady = 10)\n",
    "    \n",
    "        PIL_submit_button = tk.Button(root, text=\"Submit\", command=PIL, font=(\"Arial\", 15), width=25, height=2, activebackground=\"light green\", activeforeground=\"black\", bg=\"gray\", fg=\"white\")\n",
    "        PIL_submit_button.pack(pady = 10)\n",
    "    \n",
    "        PIL_Back = tk.Button(root, text=\"Back\", command=back2, font=(\"Arial\", 15), width=25, height=2, activebackground=\"light green\", activeforeground=\"black\", bg=\"gray\", fg=\"white\")\n",
    "        PIL_Back.pack(pady = 10)\n",
    "    \n",
    "    def button3_clicked():\n",
    "        # Removing all the elements of the main menu \n",
    "        label0.destroy()\n",
    "        label1.destroy()\n",
    "        label2.destroy()\n",
    "        button1.destroy()\n",
    "        button2.destroy()\n",
    "        button3.destroy()  \n",
    "        button4.destroy()  \n",
    "        \n",
    "        # Creating the Train menu\n",
    "        global T_label0, T_label1, T_label2, T_label3, T_entry, T_submit_button, T_Back\n",
    "        T_label0 = tk.Label(root, text=\"\", bg=Color, font=(\"Arial\", 10), padx=1, pady=1, height=1, width = 25)\n",
    "        T_label0.pack()\n",
    "        T_label1 = tk.Label(root, text=\"Train\", bg=\"gray\", fg=\"white\", font=(\"Arial\", 25), relief=\"ridge\", padx=10, pady=10, height=1, width = 25)\n",
    "        T_label1.pack()\n",
    "        T_label2 = tk.Label(root, text=\"\", bg=Color, font=(\"Arial\", 25), padx=5, pady=10, height=1, width = 25)\n",
    "        T_label2.pack()\n",
    "    \n",
    "        T_label3 = tk.Label(root, text=\"Number of epochs\", bg=Color, fg=\"white\", font=(\"Arial\", 15), padx=10, pady=10, height=1, width = 25)\n",
    "        T_label3.pack()\n",
    "    \n",
    "        T_entry = tk.Entry(root, bg=\"white\", fg=\"black\", font=(\"Arial\", 10), relief=\"ridge\", width=65)\n",
    "        T_entry.pack(pady = 10)\n",
    "\n",
    "        T_submit_button = tk.Button(root, text=\"Submit\", command=T, font=(\"Arial\", 15), width=25, height=2, activebackground=\"light green\", activeforeground=\"black\", bg=\"gray\", fg=\"white\")\n",
    "        T_submit_button.pack(pady = 10)\n",
    "    \n",
    "        T_Back = tk.Button(root, text=\"Back\", command=back3, font=(\"Arial\", 15), width=25, height=2, activebackground=\"light green\", activeforeground=\"black\", bg=\"gray\", fg=\"white\")\n",
    "        T_Back.pack(pady = 10)\n",
    "\n",
    "    def button4_clicked():\n",
    "        model_path = 'trained_model.h5'\n",
    "        history_path = 'training_history.csv'\n",
    "        global model, history \n",
    "        model, history = load_training_data(model_path, history_path)\n",
    "        print(\"Training data imported\")\n",
    "    \n",
    "    def main_menu():   \n",
    "        # Creating the main menu\n",
    "        global label0, label1, label2, button1, button2, button3, button4\n",
    "        label0 = tk.Label(root, text=\"\", bg=Color, font=(\"Arial\", 10), padx=1, pady=1, height=1, width = 25)\n",
    "        label0.pack()\n",
    "        label1 = tk.Label(root, text=\"Dog Breed Identifier\", bg=\"gray\", fg=\"white\", font=(\"Arial\", 25), relief=\"ridge\", padx=10, pady=10, height=1, width = 25)\n",
    "        label1.pack()\n",
    "        label2 = tk.Label(root, text=\"\", bg=Color, font=(\"Arial\", 25), padx=5, pady=10, height=1, width = 25)\n",
    "        label2.pack()\n",
    "        \n",
    "        button1 = tk.Button(root, text=\"Predict Image Online\", command=button1_clicked, font=(\"Arial\", 15), width=25, height=2, activebackground=\"light green\", activeforeground=\"black\", bg=\"gray\", fg=\"white\")\n",
    "        button1.pack(pady = 5)\n",
    "    \n",
    "        button2 = tk.Button(root, text=\"Predict Image Local\", command=button2_clicked, font=(\"Arial\", 15), width=25, height=2, activebackground=\"light green\", activeforeground=\"black\", bg=\"gray\", fg=\"white\")\n",
    "        button2.pack(pady = 5)\n",
    "    \n",
    "        button3 = tk.Button(root, text=\"Train\", command=button3_clicked, font=(\"Arial\", 15), width=25, height=2, activebackground=\"light green\", activeforeground=\"black\", bg=\"gray\", fg=\"white\")\n",
    "        button3.pack(pady = 5)\n",
    "\n",
    "        button4 = tk.Button(root, text=\"Import Training Data\", command=button4_clicked, font=(\"Arial\", 15), width=25, height=2, activebackground=\"light green\", activeforeground=\"black\", bg=\"gray\", fg=\"white\")\n",
    "        button4.pack(pady = 5)\n",
    "        \n",
    "        root.mainloop()\n",
    "        \n",
    "    # Creating the popup window \n",
    "    root = tk.Tk()\n",
    "    root.title(\"Dog Breed Identifier\")\n",
    "    root.geometry(\"800x600\")\n",
    "    root.configure(bg=Color)\n",
    "    \n",
    "    main_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17daf205-534b-4645-8945-0d6c311984c3",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff192d-1f18-4ce6-80e8-93963115bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_in = 20\n",
    "train(epochs_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b902cf17-0ace-47ef-9b15-ba08b86ec4de",
   "metadata": {},
   "source": [
    "## Loading previously saved training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65c670-bd61-4df6-91c0-91576c4e5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'trained_model.h5'\n",
    "history_path = 'training_history.csv'\n",
    "\n",
    "model, history = load_training_data(model_path, history_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vUDDwgpqpGYW",
   "metadata": {
    "id": "vUDDwgpqpGYW"
   },
   "source": [
    "## Download and predict images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc90152-b5f3-431e-951d-f07ea96e9dbb",
   "metadata": {
    "id": "4fc90152-b5f3-431e-951d-f07ea96e9dbb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_and_predict(\"https://cdn.pixabay.com/photo/2016/01/05/17/51/maltese-1123016_960_720.jpg\",\"test_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca86f8-897d-432e-8974-1bcc06420a3b",
   "metadata": {
    "id": "99ca86f8-897d-432e-8974-1bcc06420a3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_and_predict(\"https://t3.ftcdn.net/jpg/01/71/99/74/360_F_171997457_zUbFZOCpqgbdkPRqsrxo2dUAKIZyGTB5.jpg\",\"test_2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1e380-1d15-4ab4-b7a3-fa0626efe1bb",
   "metadata": {
    "id": "13e1e380-1d15-4ab4-b7a3-fa0626efe1bb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_and_predict(\"https://www.purina.co.uk/sites/default/files/styles/square_medium_440x440/public/2022-09/Pomeranian.jpg?\",\"test_3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfcebd-5d53-4343-b2f8-9e6eabc04968",
   "metadata": {
    "id": "63dfcebd-5d53-4343-b2f8-9e6eabc04968",
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_and_predict(\"https://image.petmd.com/files/styles/978x550/public/2023-08/australian-kelpie.jpg\",\"test_4.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386417d8-4549-4f50-9630-013ea418ea7f",
   "metadata": {
    "id": "386417d8-4549-4f50-9630-013ea418ea7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_and_predict(\"https://www.rover.com/blog/wp-content/uploads/2019/12/airedale-terrier.jpg\",\"test_5.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t0_jJlV-pKin",
   "metadata": {
    "id": "t0_jJlV-pKin"
   },
   "source": [
    "## Predict images that are already downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f538cbc-d15a-4026-bc3e-3961a45c3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"local_test_6.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f531361-1e23-44a8-a25e-2843e856ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"local_test_7.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd30ea-01a5-4591-a9c4-c3ac6100a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"local_test_8.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af72e152-a083-44fa-98bb-ada8ba18909b",
   "metadata": {},
   "source": [
    "## Reform Images\n",
    "Only needed when new images are put in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b183b215-c2a1-4c66-b5f3-20dc89f9675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Reform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b067ad-4064-4418-a159-0510e12a7266",
   "metadata": {},
   "source": [
    "## Start the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0009cfa-443e-40f6-a700-989f6e8da8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GUI()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Oign0gzFNNaS"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
